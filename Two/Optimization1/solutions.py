# name this file 'solutions.py'
"""Volume II Lab 13: Optimization Packages I (scipy.optimize)
<Name>
<Class>
<Date>
"""
from __future__ import division
import numpy as np
import scipy.optimize as opt

def prob1():
    """Use the minimize() function in the scipy.optimize package to find the
    minimum of the Rosenbrock function (scipy.optimize.rosen) using the
    following methods:
        Nelder-Mead
        Powell
        CG
        BFGS
        Newton-CG (test with and without the hessian)
        Anneal
        L-BFGS-B
        TNC
        COBYLA
        SLSQP
    Use x0 = np.array([4., -2.5]) for the initial guess for each test.
    
    Print a statement answering the following questions:
        Which algorithm(s) take(s) the least number of iterations?
        Which algorithm(s) fail to find the (correct) minimum?
    """
    x0 = np.array([4.,-2.5])
    
    opt.minimize(opt.rosen, x0, method='Nelder-Mead')
    # Nelder-Mead. solution: [ 0.99998915,  0.99997782]    nit: 67
    
    opt.minimize(opt.rosen, x0, method='Powell')
    # Powell. solution: [ 1., 1.]    nit: 19
    
    opt.minimize(opt.rosen, x0, method='CG')
    # CG. solution: [ 0.99999541,  0.99999082]    nit: 37
    
    opt.minimize(opt.rosen, x0, method='BFGS')
    # BFGS. solution: [ 0.99999551,  0.999991  ]    nit: 36

    opt.minimize(opt.rosen, x0, method='Newton-CG', jac=opt.rosen_der)
    # Newton-CG w/o hess. solution: [ 1.00000005,  1.00000011]    nit: 34
    
    opt.minimize(opt.rosen, x0, method='Newton-CG', jac=opt.rosen_der, hess=opt.rosen_hess)
    # Newton-CG w/ hess. solution: [ 0.99999997,  0.99999993]    nit: 34
    
    opt.minimize(opt.rosen, x0, method='L-BFGS-B')
    # L-BFGS-B. solution: [ 0.999997,  0.999994]    nit: 32
    
    opt.minimize(opt.rosen, x0, method='TNC')
    # TNC. solution: [ 0.99969338,  0.99938551]    nit: 30
    
    opt.minimize(opt.rosen, x0, method='COBYLA')
    # COBYLA. solution: [ 0.81260745,  0.6593741 ]    nit: X
    
    opt.minimize(opt.rosen, x0, method='SLSQP')
    # SLSQP. solution: [ 1.00013161,  1.00025956]    nit: 25
    
    output_string = """
    Powell was the only method that returned the exact answer and it 
    also used the fewest number of iterations.  All methods except for 
    COBYLA returned a solution that was very near [1,1]. The output for 
    COBYLA said 'maximum number of function evaluations has been 
    exceeded.' This explains why COBYLA doesn't return the correct answer."""
    
    print output_string

def prob2():
    """Explore the documentation on the function scipy.optimize.basinhopping()
    online or via IPython. Use it to find the global minimum of the multmin()
    function given in the lab, with initial point x0 = np.array([-2, -2]) and
    the Nelder-Mead algorithm. Try it first with stepsize=0.5, then with
    stepsize=0.2.

    Return the minimum value of the function with stepsize=0.2.
    Print a statement answering the following question:
        Why doesn't scipy.optimize.basinhopping() find the minimum the second
        time (with stepsize=0.2)?
    """
    def multimin(x):
        r = np.sqrt((x[0]+1)**2 + x[1]**2)
        return r**2 *(1+ np.sin(4*r)**2)
    
    x0 = np.array([-2,-2])
    correct_x = opt.basinhopping(multimin, x0, stepsize=0.5, 
                        minimizer_kwargs={'method':'nelder-mead'}).x
    
    wrong_x = opt.basinhopping(multimin, x0, stepsize=0.2, 
                        minimizer_kwargs={'method':'nelder-mead'}).x
    
    output_string = """
    When stepsize=0.2, the step is not large enough to jump out of the 
    basin. Therefore, we get the incorrect answer.
    """
    return multimin(wrong_x)

def prob3():
    """Find the roots of the system
    [       -x + y + z     ]   [0]
    [  1 + x^3 - y^2 + z^3 ] = [0]
    [ -2 - x^2 + y^2 + z^2 ]   [0]

    Returns the values of x,y,z as an array.
    """
    
    def func(x):
        return np.array([-x[0] + x[1] + x[2],
                         1 + x[0]**3 - x[1]**2 + x[2]**3,
                         -2 - x[0]**2 + x[1]**2 + x[2]**2])
    
    def jac(x):
        return np.array([[-1,1,1,],
                        [3*x[0]**2,-2*x[1], 3*x[2]**2],
                        [-2*x[0],2*x[1],2*x[2]]])

    sol = opt.root(func, [0,0,0], jac=jac, method='hybr').x
    return sol

def prob4():
    """Use the scipy.optimize.curve_fit() function to fit a heating curve to
    the data found in `heating.txt`. The first column of this file is time, and
    the second column is temperature in Kelvin.

    The fitting parameters should be gamma, C, and K, as given in Newton's law
    of cooling.

    Plot the data from `heating.txt` and the curve generated by curve_fit.
    Return the values gamma, C, K as an array.
    """
    data = np.loadtxt("heating.txt")
    def func(t,gamma,C,K):
        return 290. + 59.43/gamma + K*np.exp(-gamma*t/C)

    t = data[:,0]
    temp = data[:,1]
    
    popt,pcov = opt.curve_fit(func,t,temp)
    return popt
    
if __name__ == "__main__":
    print prob4()


    
