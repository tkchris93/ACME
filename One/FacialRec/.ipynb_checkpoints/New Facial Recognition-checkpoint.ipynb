{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "from os import walk\n",
    "from scipy.ndimage import imread\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "class FacialRec:\n",
    "    ##########Members##########\n",
    "    # F, mu, Fbar, and U\n",
    "    ###########################\n",
    "    def __init__(self,path):\n",
    "        self.initFaces(path)\n",
    "        self.initMeanImage()\n",
    "        self.initDifferences()\n",
    "        self.initEigenfaces()\n",
    "    def initFaces(self, path):\n",
    "        self.F = self.getFaces(path)\n",
    "    def initMeanImage(self):\n",
    "        self.mu = np.vstack(np.mean(self.F,axis=1))\n",
    "    def initDifferences(self):\n",
    "        self.Fbar = self.F - self.mu\n",
    "    def initEigenfaces(self):\n",
    "        self.U, s, Vt = la.svd(self.Fbar,full_matrices=False)\n",
    "    def project(self, A, s=38):\n",
    "        Ut = self.U[:,:s].T\n",
    "        A_s = Ut.dot(A)\n",
    "        return Ut, A_s\n",
    "    def findNearest(self, image, s=38):\n",
    "        Ut, Fhat = self.project(self.Fbar, s)\n",
    "        gbar = np.vstack(image) - self.mu\n",
    "        ghat = np.vstack(self.project(gbar)[1])\n",
    "        index = np.argmin(np.linalg.norm(Fhat-ghat, axis=0, ord=2))\n",
    "        return index\n",
    "    \n",
    "    def getFaces(self, path):\n",
    "        \"\"\"Traverse the directory specified by 'path' and return an array containing\n",
    "        one column vector per subdirectory.\n",
    "        For the faces94 dataset, this gives an array with just one column for each\n",
    "        face in the database. Each column corresponds to a flattened grayscale image.\n",
    "        \"\"\"\n",
    "        # Traverse the directory and get one image per subdirectory\n",
    "        faces = []\n",
    "        for (dirpath, dirnames, filenames) in walk(path):\n",
    "            for f in filenames:\n",
    "                if f[-3:]==\"jpg\": # only get jpg images\n",
    "                    # load image, convert to grayscale, flatten into vector\n",
    "                    face = imread(dirpath+\"/\"+f).mean(axis=2).ravel()\n",
    "                    faces.append(face)\n",
    "                    break\n",
    "        # put all the face vectors column-wise into a matrix\n",
    "        return np.array(faces).T\n",
    "\n",
    "def sampleFaces(n_tests, path):\n",
    "    \"\"\"Return an array containing a sample of n_tests images contained\n",
    "    in the path as flattened images in the columns of the output\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in walk(path):\n",
    "        for f in filenames:\n",
    "            if f[-3:]==\"jpg\": # only get jpg images\n",
    "                files.append(dirpath+\"/\"+f)\n",
    "\n",
    "    #Get a sample of the images\n",
    "    test_files = random.sample(files, n_tests)\n",
    "    #Flatten and average the pixel values\n",
    "    images = np.array([imread(f).mean(axis=2).ravel() for f in test_files]).T\n",
    "    return images\n",
    "\n",
    "def show(im, w=200, h=180):\n",
    "    \"\"\"Plot the flattened grayscale image 'im' of width 'w' and height 'h'.\"\"\"\n",
    "    plt.imshow(im.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.show()\n",
    "    \n",
    "def show2(test_image, result, w=200, h=180):\n",
    "    \"\"\"Convenience function for plotting two flattened grayscale images of\n",
    "    the specified width and height side by side\n",
    "    \"\"\"\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"Inputed Image\")\n",
    "    plt.imshow(test_image.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"Closest Match\")\n",
    "    plt.imshow(result.reshape((w,h)), cmap=cm.Greys_r)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #run tests\n",
    "    f = FacialRec('./faces94')\n",
    "    \n",
    "    n_tests = 3\n",
    "    \n",
    "    test_images = sampleFaces(n_tests, './faces94')\n",
    "    for i in xrange(len(test_images[0])):\n",
    "        index = f.findNearest(test_images[:,i])\n",
    "        show2(test_images[:,i], f.F[:,index])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = FacialRec('./faces94')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_files, test_images = f.sampleFaces(3, './faces94')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(test_images[0])):\n",
    "    index = f.findNearest(test_images[:,i])\n",
    "    show2(test_images[:,i], f.F[:,index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Steps to do Facial Recognition\n",
    "####1. Load faces dataset\n",
    "####2. Calculate the mean face (and plot it)\n",
    "####3. Calculate the mean shifted faces (and plot the first one)\n",
    "####4. Calculate the SVD of the mean shifted faces\n",
    "####5. Project onto a subspace\n",
    "Make sure that it is clear that $\\bar{g}$ is the inputed face. \n",
    "Turn the project function into a function that returns U_hat f_hat.\n",
    "####6. Find the nearest neighbor with respect to the 2-norm.\n",
    "DIMENSIONS SUCK!! See if there is a way to make this more intuitive.\n",
    "Use np.linalg.norm instead of la.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.findNearest(test_images[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.72766885],\n",
       "       [-18.08061002],\n",
       "       [-18.33986928],\n",
       "       ..., \n",
       "       [-21.05882353],\n",
       "       [-13.44444444],\n",
       "       [ -7.95206972]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/var/host/media/removable/SD Card/ACME/One/FacialRec'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imsave(\"full.png\", f.F[:,28].reshape((200,180)),cmap=cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = test_images[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.project(g)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 153)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.project(f.Fbar)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
